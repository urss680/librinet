```html
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>Detector Facial de Cámara</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      margin: 0;
      padding: 0;
      background: #111;
      color: #fff;
      font-family: Arial, Helvetica, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
    }
    #video {
      border: 2px solid #0ff;
      border-radius: 8px;
      transform: scaleX(-1);
      background: #000;
    }
    #canvas {
      position: absolute;
      transform: scaleX(-1);
      pointer-events: none;
    }
    button {
      margin-top: 12px;
      padding: 10px 20px;
      background: #0ff;
      border: none;
      border-radius: 4px;
      font-size: 16px;
      cursor: pointer;
    }
    button:disabled {
      background: #555;
      cursor: not-allowed;
    }
  </style>
</head>
<body>
  <video id="video" width="640" height="480" autoplay muted></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  <button id="toggle">Iniciar detección</button>

  <!-- Cargar opencv.js -->
  <script src="https://cdn.jsdelivr.net/npm/opencv-js@4.7.0/opencv.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const btn = document.getElementById('toggle');

    let streaming = false;
    let intervalId = null;
    let classifier = null;

    btn.addEventListener('click', () => {
      if (!streaming) start();
      else stop();
    });

    function start() {
      navigator.mediaDevices.getUserMedia({ video: true, audio: false })
        .then(stream => {
          video.srcObject = stream;
          video.play();
          streaming = true;
          btn.textContent = 'Detener detección';
          detect();
        })
        .catch(err => alert('Error al acceder a la cámara: ' + err));
    }

    function stop() {
      video.srcObject?.getTracks().forEach(t => t.stop());
      streaming = false;
      btn.textContent = 'Iniciar detección';
      clearInterval(intervalId);
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }

    function detect() {
      classifier = new cv.CascadeClassifier();
      classifier.load('https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml');

      intervalId = setInterval(() => {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const src = cv.imread(canvas);
        const gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        const faces = new cv.RectVector();
        classifier.detectMultiScale(gray, faces);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.strokeStyle = '#0f0';
        ctx.lineWidth = 2;
        for (let i = 0; i < faces.size(); ++i) {
          const f = faces.get(i);
          const centerX = f.x + f.width / 2;
          const centerY = f.y + f.height / 2;
          const radius = Math.max(f.width, f.height) / 2;
          ctx.beginPath();
          ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
          ctx.stroke();
        }
        src.delete(); gray.delete(); faces.delete();
      }, 1000 / 15); // 15 FPS
    }
  </script>
</body>
</html>
```