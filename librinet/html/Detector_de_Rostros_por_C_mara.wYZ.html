```html
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Detector de Rostros por C치mara</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: #0d0d0d;
            color: #eee;
            font-family: Arial, Helvetica, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
        }
        h1 {
            margin-bottom: 20px;
            font-size: 2em;
            letter-spacing: 1px;
        }
        #video, #canvas {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            border: 2px solid #00ff00;
            border-radius: 8px;
            box-shadow: 0 0 20px rgba(0, 255, 0, 0.4);
        }
        #canvas {
            pointer-events: none;
        }
        #status {
            position: absolute;
            bottom: 30px;
            font-size: 1.2em;
            background: rgba(0, 0, 0, 0.5);
            padding: 8px 16px;
            border-radius: 4px;
        }
    </style>
</head>
<body>
    <h1>Detector de Rostros por C치mara</h1>
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <div id="status">Cargando modelo...</div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection@1.0.2/dist/face-detection.min.js"></script>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusEl = document.getElementById('status');

        let detector;

        async function init() {
            // Cargar el modelo MediaPipe FaceDetector
            const model = faceDetection.SupportedModels.MediaPipeFaceDetector;
            detector = await faceDetection.createDetector(model, {
                runtime: 'tfjs',
                maxFaces: 10,
            });
            statusEl.textContent = 'Modelo listo. Iniciando c치mara...';

            // Acceso a la c치mara
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;

            video.onloadedmetadata = () => {
                statusEl.textContent = 'Detectando rostros...';
                detectFaces();
            };
        }

        async function detectFaces() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const faces = await detector.estimateFaces(video, { flipHorizontal: false });
            ctx.strokeStyle = '#00ff00';
            ctx.lineWidth = 2;
            ctx.font = '16px Arial';
            ctx.fillStyle = '#00ff00';

            faces.forEach(face => {
                const box = face.box;
                ctx.strokeRect(box.xMin, box.yMin, box.width, box.height);
                ctx.fillText('Rostro', box.xMin, box.yMin - 5);
            });

            requestAnimationFrame(detectFaces);
        }

        init().catch(err => {
            statusEl.textContent = 'Error: ' + err.message;
        });
    </script>
</body>
</html>
```